{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to the <code>simplechatbot</code> Python package!</p> <p>See the examples in the navbar to the left!</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install git+ssh://git@github.com/devincornell/simplechatbot.git@main\n</code></pre> <p>When inside the package directory: Basic install: </p> <p><code>pip install .</code></p> <p>This package uses buildtools - see <code>pyproject.toml</code> for package details.</p>"},{"location":"#makefile","title":"Makefile","text":"<p>You can also use <code>make</code>.</p> <p>To install: </p> <pre><code>make install\nmake uninstall\n</code></pre>"},{"location":"#importing","title":"Importing","text":"<p>Basic importing works as you would expect.</p> <p><code>import simplechatbot</code></p> <p>To support backwards compatibility, I also keep old versions in the main module titled <code>vN</code> where <code>N</code> is the version number. You can change the imports to look like the following.</p> <p><code>import simplechatbot.v4 as simplechatbot</code></p>"},{"location":"#generating-documentation","title":"Generating Documentation","text":"<p>The Makefile has most of these commands, but including them here jsut in case.</p> <pre><code>pip install mkdocs\npip install mkdocs-material\n</code></pre> <p>Start Test Server</p> <pre><code>mkdocs serve\n</code></pre> <p>Build the documentation.</p> <pre><code>mkdocs build\n</code></pre> <p>Publish the documation</p> <pre><code>mkdocs gh-deploy --force\n</code></pre>"},{"location":"#example-documentation","title":"Example Documentation","text":"<p>In the Makefile I included the commands that will take example jupyter notebooks and convert them to markdown so that <code>mkdocs</code> can eventually convert them to html for the website. Simply add a notebook to the <code>site_examples</code> folder and it will be automatically converted to markdown and placed in the right folder.</p> <pre><code>EXAMPLE_NOTEBOOK_FOLDER = ./site_examples/# this is where example notebooks are stored\nEXAMPLE_NOTEBOOK_MARKDOWN_FOLDER = ./docs/examples/# this is where example notebooks are stored\n\nexample_notebooks:\n    -mkdir $(EXAMPLE_NOTEBOOK_MARKDOWN_FOLDER)\n    jupyter nbconvert --to markdown $(EXAMPLE_NOTEBOOK_FOLDER)/*.ipynb\n    mv $(EXAMPLE_NOTEBOOK_FOLDER)/*.md $(EXAMPLE_NOTEBOOK_MARKDOWN_FOLDER)\n</code></pre>"},{"location":"examples/overview/","title":"Overview","text":"<p>Brief overview of using <code>simplechatbot</code> package.</p> <pre><code>import sys\nsys.path.append('..')\n\nimport simplechatbot\n</code></pre>"},{"location":"examples/overview/#chatbot-objects","title":"<code>ChatBot</code> Objects","text":"<p><code>ChatBot</code> instances maintain the three things that define a chatbot: a chat model (or runnable), chat history, and available tools / functions.</p> <p>It may be created from any langchain chat model or runnable. For convenience, you may also instantiate directly from Ollama or </p> <p>Optional: you can use <code>APIKeyChain</code> to retrive API keys from a json file. It is a <code>dict</code> subclass with the <code>from_json_file</code> method that will simply read a json file as a dict.</p> <pre><code>from langchain_openai import ChatOpenAI\n\nkeychain = simplechatbot.devin.APIKeyChain.from_json_file('../scripts/keys.json')\n\nmodel = ChatOpenAI(model='gpt-4o-mini', api_key=keychain['openai'])\nchatbot = simplechatbot.devin.ChatBot.from_model(model=model)\nprint(chatbot)\n</code></pre> <pre><code>ChatBot(model_type=ChatOpenAI, model_name=\"gpt-4o-mini\", tools=None)\n</code></pre>"},{"location":"examples/overview/#instantiate-with-ollama-or-openai-models","title":"Instantiate with Ollama or OpenAI Models","text":"<p>If you have an ollama instance running on your machine, you can use the <code>from_ollama</code> constructor. You only need the model name and the <code>ChatOllma</code> constructor will identify the model API endpoint location as long as it is local.</p> <pre><code>chatbot = simplechatbot.devin.ChatBot.from_ollama(\n    model_name = 'llama3.1', \n)\n</code></pre> <p>You may do the same for <code>ChatOpenAI</code> using <code>from_openai</code>.</p> <pre><code>chatbot = simplechatbot.devin.ChatBot.from_openai(\n    model_name = 'gpt-4o-mini', \n    api_key=keychain['openai'],\n)\n</code></pre>"},{"location":"examples/overview/#setting-system-prompt","title":"Setting System Prompt","text":"<p>Use the <code>system_prompt</code> parameter to initialize the chatbot with instructions.</p> <pre><code>system_prompt = '''\nYou are a creative designer who has been tasked with creating a new slogan for a company.\nThe user will describe the company, and you will need to generate three slogan ideas for them.\n'''\nchatbot = simplechatbot.devin.ChatBot.from_ollama(\n    model_name = 'llama3.1', \n    system_prompt=system_prompt,\n)\n</code></pre>"},{"location":"examples/overview/#adding-tools","title":"Adding Tools","text":"<p>The <code>tools</code> parameter allows you to pass any langchain tools you want your chatbot to be able to use. You can use one of Langchain's built-in tools (such as <code>DuckDuckGoSearchResults</code>) or define your own custom tools.</p> <pre><code>from langchain_community.tools import DuckDuckGoSearchResults\n\ntools = [\n    DuckDuckGoSearchResults(\n        keys_to_include=['snippet', 'title'], \n        results_separator='\\n\\n',\n        num_results = 4,\n    ),\n]\n\nchatbot = simplechatbot.devin.ChatBot.from_ollama(\n    model_name = 'llama3.1', \n    tools=tools,\n)\n</code></pre> <p>Having a chat.</p> <pre><code>system_prompt = '''\nYour job is to answer any questions the user has.\n'''\nchatbot = simplechatbot.devin.ChatBot.from_openai(\n    model_name = 'gpt-4o-mini', \n    api_key=keychain['openai'],\n    system_prompt=system_prompt,\n    tools=tools,\n)\n\nreply = chatbot.chat('What is the capital of France?')\nreply.message.content\n</code></pre> <pre><code>'The capital of France is Paris.'\n</code></pre>"},{"location":"examples/overview/#chat-methods","title":"Chat Methods","text":"<p>The methods <code>chat</code> and <code>chat_stream</code> both send the provided message with history to the LLM for prediction.</p> <ul> <li><code>chat</code>: returns <code>ChatResult</code> instance with the AI message and ability to call tool functions with provided parameters.</li> <li><code>chat_stream</code>: returns <code>ChatStream</code> instance which allows you to iterate over responses from the LLM and call tools once all of the parameters have been provided.</li> </ul> <p>Of the two, <code>ChatResult</code> is the most straightforward, so I will discuss that first.</p>"},{"location":"examples/overview/#chatresult-objects","title":"<code>ChatResult</code> Objects","text":"<p>These are returned from calls to <code>chat</code>. Most importantly, access the <code>message</code> property to see the response directly.</p> <pre><code>reply.message.usage_metadata\n</code></pre> <pre><code>{'input_tokens': 104, 'output_tokens': 8, 'total_tokens': 112}\n</code></pre> <pre><code>reply.message.response_metadata\n</code></pre> <pre><code>{'token_usage': {'completion_tokens': 8,\n  'prompt_tokens': 104,\n  'total_tokens': 112,\n  'completion_tokens_details': {'reasoning_tokens': 0},\n  'prompt_tokens_details': {'cached_tokens': 0}},\n 'model_name': 'gpt-4o-mini-2024-07-18',\n 'system_fingerprint': 'fp_f85bea6784',\n 'finish_reason': 'stop',\n 'logprobs': None}\n</code></pre> <p>See available tool calls using <code>tool_calls</code>. This is a thin wrapper over the <code>AIMessage.tool_calls</code> property.</p> <p>See how the question about the weather in Rome results in a tool call.</p> <pre><code>chatbot.chat('What is the capital of France?').tool_calls\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>reply = chatbot.chat('What is the weather in Rome?')\nreply.tool_calls\n</code></pre> <pre><code>[{'name': 'duckduckgo_results_json',\n  'args': {'query': 'current weather in Rome'},\n  'id': 'call_wF7eMhgRjPAR3CNmlXQyuJZW',\n  'type': 'tool_call'}]\n</code></pre> <p>Make a call to <code>call_tools()</code> to actually execute the tools. The results are returned as dicts with tool names as keys pointing to return values.</p> <pre><code>tool_call_results = reply.call_tools()\nfor tool_name, result in tool_call_results.items():\n    print(result.tool_info_str)\n</code></pre> <pre><code>duckduckgo_results_json(query=current weather in Rome)\n</code></pre>"},{"location":"examples/overview/#chatstream-objects","title":"<code>ChatStream</code> Objects","text":"<p>Calls to <code>chat_stream</code> are very similar but instead return <code>ChatStream</code> objects. These objects are iterators and must be iterated over before you can call any tools. If you are not expecting any tool calls, you can call <code>chat_stream</code> directly in the loop.</p> <pre><code>for r in chatbot.chat_stream(f'What is the capital of France?'):\n    print(r.content, end='', flush=True)\n</code></pre> <pre><code>The capital of France is Paris.\n</code></pre> <p>If you want to be able to call tools, iterate through the reply chunks before calling the tools. After exhausting the iterable, you can call <code>call_tools</code> to see and execute the requested tools. You can also use the <code>tool_calls</code> property to see if there are any tools to be called.</p> <pre><code>reply_stream = chatbot.chat_stream(f'What is the weather in Rome?')\nfor r in reply_stream:\n    print(r.content, end='', flush=True)\n\nreply_stream.tool_calls\n</code></pre> <pre><code>The current weather in Rome is sunny, with a few clouds expected. The temperature is peaking at around 79\u00b0F. During the night and early morning, there will be light air, and in the afternoon, a light breeze is anticipated, with gusts possibly reaching up to 21 mph.\n\n\n\n\n[]\n</code></pre> <p>Note: do not call <code>call_tools</code> before completing the iterable because the chatbot may not have streamed all of the tool call information back.</p>"},{"location":"examples/overview/#chat-user-interface","title":"Chat User Interface","text":"<p>Of course, what is a chatbot if you can't actually use it? To run an interactive command-line chat, use <code>.ui.start_interactive</code>.</p> <pre><code># uncomment to start interactive chat\n#chatbot.ui.start_interactive(stream=True, show_intro=True, show_tools=True)\n</code></pre>"}]}