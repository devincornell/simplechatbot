{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to the <code>simplechatbot</code> Python package! This package provides tools for working with LLM agents - in particular, chatbots that track tools and conversation history.</p> <p>See the examples in the navigation bar to the left!</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install git+ssh://git@github.com/devincornell/simplechatbot.git@main\n</code></pre> <p>When inside the package directory: Basic install: </p> <p><code>pip install .</code></p> <p>This package uses buildtools - see <code>pyproject.toml</code> for package details.</p>"},{"location":"#makefile","title":"Makefile","text":"<p>You can also use <code>make</code>.</p> <p>To install: </p> <pre><code>make install\nmake reinstall\nmake uninstall\n</code></pre>"},{"location":"#importing","title":"Importing","text":"<p>Basic importing works as you would expect.</p> <p><code>import simplechatbot</code></p>"},{"location":"#generating-documentation","title":"Generating Documentation","text":"<p>The Makefile has most of these commands, but including them here jsut in case.</p> <pre><code>pip install mkdocs\npip install mkdocs-material\n</code></pre> <p>Start Test Server</p> <pre><code>mkdocs serve\n</code></pre> <p>Build the documentation.</p> <pre><code>mkdocs build\n</code></pre> <p>Publish the documation</p> <pre><code>mkdocs gh-deploy --force\n</code></pre>"},{"location":"#example-documentation","title":"Example Documentation","text":"<p>In the Makefile I included the commands that will take example jupyter notebooks and convert them to markdown so that <code>mkdocs</code> can eventually convert them to html for the website. Simply add a notebook to the <code>site_examples</code> folder and it will be automatically converted to markdown and placed in the right folder.</p> <pre><code>EXAMPLE_NOTEBOOK_FOLDER = ./site_examples/# this is where example notebooks are stored\nEXAMPLE_NOTEBOOK_MARKDOWN_FOLDER = ./docs/examples/# this is where example notebooks are stored\n\nexample_notebooks:\n    -mkdir $(EXAMPLE_NOTEBOOK_MARKDOWN_FOLDER)\n    python -m pymddoc ipynb2md-multi $(EXAMPLE_NOTEBOOK_FOLDER)/*.ipynb\n    mv $(EXAMPLE_NOTEBOOK_FOLDER)/*.md $(EXAMPLE_NOTEBOOK_MARKDOWN_FOLDER)\n</code></pre>"},{"location":"examples/a-overview/","title":"API Introduction","text":"<p>This is a brief introduction to the <code>simplechatbot</code> API.</p> <pre><code>import sys\nsys.path.append('../src/')\n\nimport simplechatbot\n</code></pre>"},{"location":"examples/a-overview/#instantiating-agent-objects","title":"Instantiating <code>Agent</code> Objects","text":"<p><code>Agent</code> instances maintain three elements: a chat model (or runnable) LLM, chat history, and available tools / functions. System prompts are simply stored as part of the conversation history.</p> <p>It may be instantiated from any langchain chat model or runnable.</p> <pre><code>from langchain_openai import ChatOpenAI\n\n# optional: use this to grab keys from a json file rather than setting system variables\nkeychain = simplechatbot.APIKeyChain.from_json_file('../keys.json')\n\nopenai_model = ChatOpenAI(model='gpt-4o-mini', api_key=keychain['openai'])\nagent = simplechatbot.Agent.from_model(model=openai_model)\nprint(agent)\n</code></pre> <p>stdout:</p> <pre><code>Agent(model_type=ChatOpenAI, model_name=\"gpt-4o-mini\", tools=ToolLookup(tools={}))\n</code></pre> <p>Set a system prompt for the agent by passing it as the <code>system_prompt</code> argument.</p> <pre><code>system_prompt = '''\nYou are a creative designer who has been tasked with creating a new slogan for a company.\nThe user will describe the company, and you will need to generate three slogan ideas for them.\n'''\nagent = simplechatbot.Agent.from_model(\n    model = openai_model,\n    system_prompt=system_prompt,\n)\n</code></pre> <p>The <code>tools</code> parameter allows you to pass any langchain tools you want your agent to be able to use. You can use one of Langchain's built-in tools (such as <code>FileManagementToolkit</code>) or define your own custom tools. I will use <code>FileManagementToolkit</code> for demonstration purposes here.</p> <pre><code>import langchain_core.tools\n\n@langchain_core.tools.tool\ndef check_new_messages(text: str, username: str) -&gt; str:\n    '''Check messages.'''\n    return f'No new messages.'\n\nagent = simplechatbot.Agent.from_model(\n    model = openai_model,\n    tools = [check_new_messages],\n)\n</code></pre> <p>You can see that tools are added to an internal <code>ToolSet</code> object.</p> <pre><code>agent.toolset\n</code></pre> <p>text:</p> <pre><code>ToolSet(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;)}, tool_factories=[], tool_choice=None)\n</code></pre> <p>While the LLM itself is just a function, we build conversation-like behavior by storing a chat history. In <code>simplechatbot</code>, the history is stored in a <code>ChatHistory</code>, which is just a list subtype where list elements contain langchain <code>BaseMessage</code> subtypes. You can access it through the <code>history</code> property, and work with it just as a list.</p> <p>Here you can see that the system prompt is simply added as the first message in the agent history. </p> <pre><code>agent.history\n</code></pre> <p>text:</p> <pre><code>[]\n</code></pre> <p>To see the conversation history that is sent to the LLM, you can use the <code>get_buffer_string</code> method. This uses the same langchain methods used to invoke the LLM, so it is useful for debugging.</p> <pre><code>print(agent.history.get_buffer_string())\n</code></pre> <p>stdout:</p> <p>Note that history is a <code>list</code> subtype, so you can iterate through messages as you would expect.</p> <pre><code>for m in agent.history:\n    print(m)\n</code></pre>"},{"location":"examples/a-overview/#high-level-chat-and-stream-methods","title":"High-level <code>chat</code> and <code>stream</code> Methods","text":"<p>There are two primary methods used to interact with the chatbot: <code>chat</code> and <code>stream</code>. </p> <p>These are the method use-cases:</p> <p><code>.chat()</code> \u2192 <code>ChatResult</code>: Use when you want to retrieve the full LLM response at once when it finishes.</p> <p><code>.stream()</code> \u2192 <code>ChatStream</code>: Use when you would like to show intermediary results to the user as they are received from the LLM.</p> <pre><code>agent.chat('My name is Devin.')\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=Nice to meet you, Devin! How can I assist you today?, tool_calls=[])\n</code></pre> <pre><code>agent.stream('My name is Devin and I am a creative designer.')\n</code></pre> <p>text:</p> <pre><code>StreamResult(message_iter=&lt;generator object RunnableBindingBase.stream at 0x131542d40&gt;, agent=Agent(model_type=ChatOpenAI, model_name=\"gpt-4o-mini\", tools=ToolLookup(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;)})), tool_lookup=ToolLookup(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;)}), add_reply_to_history=True, full_message=AIMessageChunk(content='', additional_kwargs={}, response_metadata={}), exhausted=False, receive_callback=None)\n</code></pre> <p>Again use the <code>get_buffer_string</code> method to conveniently view the chat history.</p> <pre><code>print(agent.history.get_buffer_string())\n</code></pre> <p>stdout:</p> <pre><code>Human: My name is Devin.\nAI: Nice to meet you, Devin! How can I assist you today?\nHuman: My name is Devin and I am a creative designer.\n</code></pre> <p>From the response to the prompt below you can see that it is maintained in the chat history because it \"retains\" knowledge that is given to it.</p> <pre><code>agent.chat('I have a quiz for you: what is my name?')\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=Your name is Devin!, tool_calls=[])\n</code></pre>"},{"location":"examples/a-overview/#chat-and-chatresult-objects","title":"<code>.chat()</code> and <code>ChatResult</code> Objects","text":"<p>The <code>chat</code> method submits the current message and all history to the LLM and returns the reply as a <code>ChatResult</code> object.</p> <pre><code>agent.chat('Hello world.')\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=Hello, Devin! How are you today?, tool_calls=[])\n</code></pre> <p>If you want to submit the current chat history but do not want to add a new message, you can pass <code>None</code> as the message argument.</p> <pre><code>agent.chat(None)\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=Is there anything specific you'd like to discuss or any questions you have?, tool_calls=[])\n</code></pre> <p>Alternatively, if you want to submit a query to the LLM but do not want to save it in the history, set <code>add_to_history = False</code>.</p> <pre><code>agent.chat('Hello world.', add_to_history=False)\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=Hello again, Devin! If there's anything specific you'd like to talk about or if you have any questions, feel free to share!, tool_calls=[])\n</code></pre> <p><code>ChatResult</code> objects are returned from <code>chat()</code> and <code>invoke()</code> calls and include the LLM response text or tool calling information.</p> <pre><code>result = agent.chat('What is my name?')\nresult\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=Your name is Devin., tool_calls=[])\n</code></pre> <p>If no tool calls were requested from the LLM, you can access the response as a string through the <code>content</code> property.</p> <pre><code>result.content\n</code></pre> <p>text:</p> <pre><code>'Your name is Devin.'\n</code></pre> <p>If tool calls were made, the content will be empty but you can get information about any tool calls through the <code>tool_calls</code> attribute. Notice that no tool calls were requested by the LLM in the response to this query.</p> <pre><code>result.tool_calls\n</code></pre> <p>text:</p> <pre><code>[]\n</code></pre> <p>If there were tool calls, you can execute them using the <code>execute_tools</code> method.</p> <pre><code>result.execute_tools()\n</code></pre> <p>text:</p> <pre><code>{}\n</code></pre> <p>We provided the agent with a tool called <code>check_new_messages</code> earlier, and the LLM will request a tool call if the user requests it.</p> <pre><code>result = agent.chat('Check new messages.')\nresult.tool_calls\n</code></pre> <p>text:</p> <pre><code>[ToolCallInfo(id='call_208aNIO1I1TlXxijnOdWYQFf', name='check_new_messages', type='tool_call', args={'text': 'Check new messages.', 'username': 'Devin'}, tool=StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;))]\n</code></pre> <p>The <code>execute_tools</code> method returns a dictionary of <code>ToolCallResult</code> objects which contain the tool call information from the LLM (<code>ToolCallInfo</code>) and the return value of the tool execution.</p> <pre><code>tool_results = result.execute_tools()\ntool_results\n</code></pre> <p>text:</p> <pre><code>{'check_new_messages': ToolCallResult(info=ToolCallInfo(id='call_208aNIO1I1TlXxijnOdWYQFf', name='check_new_messages', type='tool_call', args={'text': 'Check new messages.', 'username': 'Devin'}, tool=StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;)), return_value='No new messages.')}\n</code></pre> <p>Use the <code>return_value</code> attribute to access these results.</p> <pre><code>tool_results['check_new_messages'].return_value\n</code></pre> <p>text:</p> <pre><code>'No new messages.'\n</code></pre>"},{"location":"examples/a-overview/#stream-and-streamresult-objects","title":"<code>.stream()</code> and <code>StreamResult</code> Objects","text":"<p><code>stream</code> is very similar to <code>chat</code>, but allows you to return content to the user as soon as the LLM produces it. The method returns a <code>StreamResult</code> object which has an iterator interface that accumulates results from the LLM while also returning incremental results.</p> <p>In this example, I call <code>stream</code> to retrieve a <code>StreamResult</code> object, which I then iterate through to retrieve and print all results.</p> <pre><code>stream = agent.stream('What is my name?')\nfor r in stream:\n    print(r.content, end='', flush=True)\nstream\n</code></pre> <p>stdout:</p> <pre><code>Your name is Devin.\n</code></pre> <p>text:</p> <pre><code>StreamResult(message_iter=&lt;generator object RunnableBindingBase.stream at 0x1229117b0&gt;, agent=Agent(model_type=ChatOpenAI, model_name=\"gpt-4o-mini\", tools=ToolLookup(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;)})), tool_lookup=ToolLookup(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;)}), add_reply_to_history=True, full_message=AIMessageChunk(content='Your name is Devin.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306'}), exhausted=True, receive_callback=None)\n</code></pre> <p>You can check the <code>exhausted</code> flag to see if the LLM has returned all results yet.</p> <pre><code>stream = agent.stream('What is my name?')\nprint(stream.exhausted)\nfor r in stream:\n    print(r.content, end='', flush=True)\nprint(stream.exhausted)\nstream\n</code></pre> <p>stdout:</p> <pre><code>False\nYour name is Devin.True\n</code></pre> <p>text:</p> <pre><code>StreamResult(message_iter=&lt;generator object RunnableBindingBase.stream at 0x1315422f0&gt;, agent=Agent(model_type=ChatOpenAI, model_name=\"gpt-4o-mini\", tools=ToolLookup(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;)})), tool_lookup=ToolLookup(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;)}), add_reply_to_history=True, full_message=AIMessageChunk(content='Your name is Devin.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306'}), exhausted=True, receive_callback=None)\n</code></pre> <p>After retrieving all of the LLM response, you can check if any tool calls are required.</p> <pre><code>stream = agent.stream('Check my messages.')\nfor r in stream:\n    print(r.content, end='', flush=True)\nstream.tool_calls\n</code></pre> <p>text:</p> <pre><code>[ToolCallInfo(id='call_wxhHcOtuj5XPSHvnbFVvOXrQ', name='check_new_messages', type='tool_call', args={'text': 'Check my messages.', 'username': 'Devin'}, tool=StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;))]\n</code></pre> <p>And you would similarly execute tools by calling <code>execute_tools</code>. Note that you cannot call this method if the stream has not been exhausted.</p> <pre><code>stream.execute_tools()\n</code></pre> <p>text:</p> <pre><code>{'check_new_messages': ToolCallResult(info=ToolCallInfo(id='call_wxhHcOtuj5XPSHvnbFVvOXrQ', name='check_new_messages', type='tool_call', args={'text': 'Check my messages.', 'username': 'Devin'}, tool=StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x131f511c0&gt;)), return_value='No new messages.')}\n</code></pre> <p>You can use the <code>result</code> method to get a <code>ChatResult</code> object instead. If it has not retrieved all results from the LLM, it will do so before returning.</p> <pre><code>agent.stream('Hello world.').collect()\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=Hello again, Devin! What would you like to talk about?, tool_calls=[])\n</code></pre>"},{"location":"examples/a-overview/#low-level-llm-methods-_invoke-and-_stream","title":"Low-level LLM Methods: <code>_invoke</code> and <code>_stream</code>","text":"<p>These lower-level <code>_invoke</code> and <code>_stream</code> methods are used by the <code>chat</code> and <code>chat_stream</code> methods to submit prompts to the LLM. They can allow you to interact with the LLM and tools/functions without chat history. Their signatures are very similar to high-level methods and they return the same types.</p> <p>NOTE: These methods ignore the system prompt!</p> <p>The low-level <code>_invoke</code> method returns a <code>ChatResult</code> object with the content and tool call information.</p> <pre><code>result = agent._invoke('Hello world!')\nresult\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=Hello! How can I assist you today?, tool_calls=[])\n</code></pre> <p>And <code>stream</code> is very similar to <code>stream</code> except that it ignores chat history.</p> <pre><code>stream = agent._stream('Check messages.')\nfor r in stream:\n    print(r.content, end='', flush=True)\nstream.execute_tools()\n</code></pre> <p>stdout:</p> <pre><code>Can you please provide your username and the message you would like to check?\n</code></pre> <p>text:</p> <pre><code>{}\n</code></pre>"},{"location":"examples/a-overview/#chat-user-interface","title":"Chat User Interface","text":"<p>Of course, what is a chatbot if you can't actually use it? To run an interactive command-line chat, use <code>.ui.start_interactive</code>.</p> <pre><code># uncomment to start interactive chat\n#agent.ui.start_interactive(stream=True, show_intro=True, show_tools=True)\n</code></pre>"},{"location":"examples/b-model_specific_chatbots/","title":"Model-specific ChatBots","text":"<p>While <code>ChatBot</code> instances can be created from any Langchain Chat interface, we created some convenient superclasses that have varying levels of model-specific behavior.</p> <p>Model-specific chatbots only differ from <code>ChatBot</code> in that they define static factory constructor methods, all named <code>new</code>. As each chat model needs to be installed separately, they must be accessed via separate imports.</p> <pre><code>import sys\nsys.path.append('../src/')\n\nimport simplechatbot\n</code></pre> <p>I will use the keychain to manage API keys for OpenAI and Mistral.</p> <pre><code>keychain = simplechatbot.APIKeyChain.from_json_file('../keys.json')\n</code></pre> <p>Notice that we use a separate import statement to explicitly import the model-specific chatbots.</p> <pre><code>from simplechatbot.ollama_agent import OllamaAgent\n\nagent = OllamaAgent.new(\n    model_name = 'llama3.1', \n)\n</code></pre> <pre><code>from simplechatbot.openai_agent import OpenAIAgent\n\nagent = OpenAIAgent.new(\n    model_name = 'gpt-4o-mini', \n    api_key=keychain['openai'],\n)\n</code></pre> <pre><code>from simplechatbot.mistral_agent import MistralAgent\n\nagent = MistralAgent.new(\n    model_name = 'mistral-large-latest', \n    api_key=keychain['mistral'],\n)\n</code></pre>"},{"location":"examples/c-structured_outputs/","title":"Structured Outputs","text":"<p>One of the most powerful features of LLMs is the ability to produce outputs which conform to a pre-determined structure. There are several instances in which this feature is critical.</p> <ul> <li>Output structures may enforce \"reasoning\" or systematic approaches to generating responses.</li> <li>The output must be passed to an application or interface that is not simply text-based.</li> </ul> <p>We define output structures using custom Pydantic types with attribute descriptions and validation logics. See more about using Pydantic types for structured outputs using langchain here. This package builds on that functionality by making it easy to request structured output at any point in an exchange.</p> <pre><code>import pydantic\n\nimport sys\nsys.path.append('../src/')\n\nimport simplechatbot\nfrom simplechatbot.openai_agent import OpenAIAgent\n</code></pre> <p>Create a new basic agent with no system prompt and no tools.</p> <pre><code># optional: use this to grab keys from a json file rather than setting system variables\nkeychain = simplechatbot.APIKeyChain.from_json_file('../keys.json')\n\nagent = OpenAIAgent.new('gpt-4o-mini', api_key=keychain['openai'])\nprint(agent)\n</code></pre> <p>stdout:</p> <pre><code>OpenAIAgent(model_type=ChatOpenAI, model_name=\"gpt-4o-mini\", tools=ToolLookup(tools={}))\n</code></pre> <p>Note that this is a normal agent that can be conversed with.</p> <pre><code>agent.stream('Hello, how are you? My name is Devin. Don\\'t forget it!').print_and_collect()\n</code></pre> <p>stdout:</p> <pre><code>Hello, Devin! I'm doing well, thank you. How can I assist you today?\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=Hello, Devin! I'm doing well, thank you. How can I assist you today?, tool_calls=[])\n</code></pre>"},{"location":"examples/c-structured_outputs/#pydantic-types-and-chat_structured","title":"Pydantic Types and <code>chat_structured</code>","text":"<p>The <code>chat_structured</code> method allows you to provide an output structure that the LLM response will be constrained to. The example below forces the LLM to answer the question and even come up with a follow-up question.</p> <pre><code>class ResponseFormatter(pydantic.BaseModel):\n    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n    answer: str = pydantic.Field(description=\"The answer to the user's question.\")\n    followup_question: str = pydantic.Field(description=\"A follow-up question the user could ask.\")\n\nsresult = agent.chat_structured('what is your favorite cat?', output_structure=ResponseFormatter)\nsresult\n</code></pre> <p>text:</p> <pre><code>StructuredOutputResult(data=answer=\"As an AI, I don't have personal preferences or feelings, but popular cat breeds that many people love include the Maine Coon for their friendly nature and size, the Siamese for their vocal personality, and the Ragdoll for their affectionate demeanor. What about you, Devin? Do you have a favorite cat?\" followup_question='What qualities do you look for in a favorite cat?')\n</code></pre> <p>As you can see, the <code>chat_structured</code> method returns a <code>StructuredOutputResult</code> instance, which has a <code>data</code> attribute which actually stores the Pydantic type instance.</p> <pre><code>sresult.data\n</code></pre> <p>text:</p> <pre><code>ResponseFormatter(answer=\"As an AI, I don't have personal preferences or feelings, but popular cat breeds that many people love include the Maine Coon for their friendly nature and size, the Siamese for their vocal personality, and the Ragdoll for their affectionate demeanor. What about you, Devin? Do you have a favorite cat?\", followup_question='What qualities do you look for in a favorite cat?')\n</code></pre> <p>Access the attributes of the response through this instance.</p> <pre><code>sresult.data.answer\n</code></pre> <p>text:</p> <pre><code>\"As an AI, I don't have personal preferences or feelings, but popular cat breeds that many people love include the Maine Coon for their friendly nature and size, the Siamese for their vocal personality, and the Ragdoll for their affectionate demeanor. What about you, Devin? Do you have a favorite cat?\"\n</code></pre> <pre><code>sresult.data.followup_question\n</code></pre> <p>text:</p> <pre><code>'What qualities do you look for in a favorite cat?'\n</code></pre> <p>You can see this object in json format using the <code>as_json</code> method.</p> <pre><code>print(sresult.as_json(indent=2))\n</code></pre> <p>stdout:</p> <pre><code>{\n  \"answer\": \"As an AI, I don't have personal preferences or feelings, but popular cat breeds that many people love include the Maine Coon for their friendly nature and size, the Siamese for their vocal personality, and the Ragdoll for their affectionate demeanor. What about you, Devin? Do you have a favorite cat?\",\n  \"followup_question\": \"What qualities do you look for in a favorite cat?\"\n}\n</code></pre> <p>You can see that the response was included in the conversation history in json format. Fortunately, modern LLMs can easily parse json data structures to keep track of conversation progress.</p> <pre><code>print(agent.history.get_buffer_string())\n</code></pre> <p>stdout:</p> <pre><code>Human: Hello, how are you? My name is Devin. Don't forget it!\nAI: Hello, Devin! I'm doing well, thank you. How can I assist you today?\nHuman: what is your favorite cat?\nAI: {\"answer\":\"As an AI, I don't have personal preferences or feelings, but popular cat breeds that many people love include the Maine Coon for their friendly nature and size, the Siamese for their vocal personality, and the Ragdoll for their affectionate demeanor. What about you, Devin? Do you have a favorite cat?\",\"followup_question\":\"What qualities do you look for in a favorite cat?\"}\n</code></pre> <p>Asking it again by passing <code>new_message=None</code> shows that it will simply ask the questions in plain text format, so it will re-use the structured response provided in the previous message.</p> <pre><code>agent.stream(None).print_and_collect()\n</code></pre> <p>stdout:</p> <pre><code>As an AI, I don't have personal preferences or feelings, but popular cat breeds that many people love include the Maine Coon for their friendly nature and size, the Siamese for their vocal personality, and the Ragdoll for their affectionate demeanor. What about you, Devin? Do you have a favorite cat?\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=As an AI, I don't have personal preferences or feelings, but popular cat breeds that many people love include the Maine Coon for their friendly nature and size, the Siamese for their vocal personality, and the Ragdoll for their affectionate demeanor. What about you, Devin? Do you have a favorite cat?, tool_calls=[])\n</code></pre>"},{"location":"examples/c-structured_outputs/#complex-structures-and-response-order","title":"Complex Structures and Response Order","text":"<p>The most powerful aspect of structured responses is that they force the LLM to provide parts of the full response separately and in-sequence. Carefully designed output structures can lead to better and more complete responses.</p> <p>In the following questions, we ask the LLM to provide a response to the question \"Why are cheetahs so fast?\" with different output structures.</p> <pre><code>class ReasonedResponse(pydantic.BaseModel):\n    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n    answer: str = pydantic.Field(description=\"The answer to the user's question.\")\n    reasons: list[str] = pydantic.Field(description=\"Reasons for the answer.\")\n\nsresult = agent.chat_structured('Why are cheetahs so fast?', output_structure=ReasonedResponse, add_to_history=False)\nprint(sresult.as_json(indent=2))\n</code></pre> <p>stdout:</p> <pre><code>{\n  \"answer\": \"Cheetahs are fast due to their unique physical adaptations and evolutionary traits.\",\n  \"reasons\": [\n    \"Cheetahs have a lightweight body structure, which reduces drag when running.\",\n    \"They possess long, powerful legs that enable rapid acceleration and speed.\",\n    \"Their flexible spine allows for an extended stride length, increasing their speed.\",\n    \"Cheetahs have large nasal passages and lungs that facilitate increased oxygen intake during high-speed chases.\"\n  ]\n}\n</code></pre> <pre><code>class ReasonedResponse2(pydantic.BaseModel):\n    \"\"\"This is a well-reasoned response.\"\"\"\n    reasons: list[str] = pydantic.Field(description=\"Reasons for the answer.\")\n    answer: str = pydantic.Field(description=\"The answer to the user's question.\")\n\nsresult = agent.chat_structured('Why are cheetahs so fast?', output_structure=ReasonedResponse2, add_to_history=False)\nprint(sresult.as_json(indent=2))\n</code></pre> <p>stdout:</p> <pre><code>{\n  \"reasons\": [\n    \"Cheetahs have a lightweight body structure and long legs designed for speed.\",\n    \"Their flexible spine allows for an extended stride length while running.\",\n    \"Muscle composition in cheetahs is optimized for quick bursts of speed, containing a high percentage of fast-twitch muscle fibers.\",\n    \"They have large nasal passages for increased oxygen intake and a specialized respiratory system that facilitates rapid breathing during sprints.\"\n  ],\n  \"answer\": \"Cheetahs are so fast due to their lightweight body, long leg structure, flexible spine, and muscle composition optimized for speed.\"\n}\n</code></pre> <p>You may also create nested response structures. In this case, we further improve reasoning abilities by requiring the LLM to self-rate the quality of its own responses, leading to a final answer which places special emphasis on these reasons.</p> <pre><code>class SingleReason(pydantic.BaseModel):\n    \"\"\"This is a single reason and a self-assessment of the quality of the reason.\"\"\"\n    reason: str = pydantic.Field(description=\"A description of the reason.\")\n    quality: int = pydantic.Field(description=\"Quality score represented by an integer between 1 and 10.\")\n\nclass ReasonedResponse3(pydantic.BaseModel):\n    \"\"\"This is a well-reasoned response.\"\"\"\n    reasons: list[SingleReason] = pydantic.Field(description=\"Reasons for the answer.\")\n    answer: str = pydantic.Field(description=\"The answer to the user's question, based on the given reasons and emphsaizing the highest quality reasons.\")\n\nsresult = agent.chat_structured('Why are cheetahs so fast?', output_structure=ReasonedResponse3, add_to_history=False)\nprint(sresult.as_json(indent=2))\n</code></pre> <p>stdout:</p> <pre><code>{\n  \"reasons\": [\n    {\n      \"reason\": \"Cheetahs have a lightweight body structure that reduces drag and allows for quicker acceleration.\",\n      \"quality\": 9\n    },\n    {\n      \"reason\": \"Their leg muscles are highly specialized for sprinting, providing powerful and rapid movement.\",\n      \"quality\": 8\n    },\n    {\n      \"reason\": \"Cheetahs possess large nostrils that allow for increased oxygen intake during a sprint, supporting their high-speed chases.\",\n      \"quality\": 7\n    },\n    {\n      \"reason\": \"Their flexible spine enables a longer stride length while running, enhancing speed.\",\n      \"quality\": 8\n    }\n  ],\n  \"answer\": \"Cheetahs are so fast due to their lightweight body structure, specialized leg muscles, large nostrils for oxygen intake, and a flexible spine that allows for longer strides.\"\n}\n</code></pre> <p>Different approaches for output structures and ordering can lead to vastly different results, so, as with most Generative AI applications, experimentation is essential!</p>"},{"location":"examples/d-tool_calling/","title":"Tool Calling","text":"<p><code>simplechatbot</code> empowers agents with the ability to produce arguments for arbitrary user functions instead of providing a text response to the user's prompt. Using this interface you can enable features such as web searching, email sending/checking, file browsing, image creation, or any other functionality that can be accessed through Python. The LLM will \"decide\" whether and which tools/functions should be executed based on a given prompt, so the key is to use tools with clear and concise instructions.</p> <p>Under the hood, <code>ChatBot</code> instances maintain a collection of langchain tools which can be extracted from toolkits or even factory methods that accept the chatbot itself as a parameter. Tools may also be added at the time of LLM execution to enable dynamic systems of available tools.</p> <p>You can create your own custom tools or choose from Langchain's built-in tools. I will use <code>FileManagementToolkit</code> for demonstration purposes here.</p> <pre><code>import sys\nsys.path.append('../src/')\n\nimport simplechatbot\nfrom simplechatbot.openai_agent import OpenAIAgent\n</code></pre>"},{"location":"examples/d-tool_calling/#enabling-tools","title":"Enabling Tools","text":"<p>Start by creating a new example tool that can enables the LLM to check email for the user. We create this tool using the <code>@langchain_core.tools.tool</code> decorator.</p> <pre><code>import langchain_core.tools\n\n@langchain_core.tools.tool\ndef check_new_messages() -&gt; str:\n    '''Check messages.'''\n    return f'No new messages.'\n</code></pre> <p>We include this tool as part of the chatbot by passing the function through the <code>tools</code> argument.</p> <pre><code>keychain = simplechatbot.APIKeyChain.from_json_file('../keys.json')\n\nsystem_prompt = '''\nYou are designed to answer any question the user has and send/check messages if needed.\nWhen the user requests you to check your messages, you should display the retrieved messages\n to the user.\n'''\n\nagent = OpenAIAgent.new(\n    model_name = 'gpt-4o-mini', \n    api_key=keychain['openai'],\n    system_prompt=system_prompt,\n    tools = [check_new_messages],\n)\n</code></pre> <p>Now the LLM will have access to these tools. While the agent instance stores the LLM object in the <code>_model</code> attribute, you can use <code>model</code> to get the LLM with bound tools.</p> <pre><code>agent.model\n</code></pre> <p>text:</p> <pre><code>RunnableBinding(bound=ChatOpenAI(client=&lt;openai.resources.chat.completions.completions.Completions object at 0x10cd3c080&gt;, async_client=&lt;openai.resources.chat.completions.completions.AsyncCompletions object at 0x10cd3dd90&gt;, root_client=&lt;openai.OpenAI object at 0x10844b6e0&gt;, root_async_client=&lt;openai.AsyncOpenAI object at 0x10cd3c0e0&gt;, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'check_new_messages', 'description': 'Check messages.', 'parameters': {'properties': {}, 'type': 'object'}}}]}, config={}, config_factories=[])\n</code></pre> <p>You can also use the method <code>get_model_with_tools</code> to get the tool-bound model with any additional tools. The <code>invoke</code>, <code>stream</code>, <code>chat</code>, and <code>chat_stream</code> methods all use this under-the hood so you can add any tools, toolkits, or tool factories to the model at invokation.</p> <pre><code>agent.get_model_with_tools(tools=None)\n</code></pre> <p>text:</p> <pre><code>(RunnableBinding(bound=ChatOpenAI(client=&lt;openai.resources.chat.completions.completions.Completions object at 0x10cd3c080&gt;, async_client=&lt;openai.resources.chat.completions.completions.AsyncCompletions object at 0x10cd3dd90&gt;, root_client=&lt;openai.OpenAI object at 0x10844b6e0&gt;, root_async_client=&lt;openai.AsyncOpenAI object at 0x10cd3c0e0&gt;, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'check_new_messages', 'description': 'Check messages.', 'parameters': {'properties': {}, 'type': 'object'}}}]}, config={}, config_factories=[]),\n ToolLookup(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x1084516c0&gt;)}))\n</code></pre> <p>Tools will be automatically used when we call any of the invoke or stream methods.</p> <p>Notice that the LLM behaves normally if the user's prompts are unrelated to the tool.</p> <pre><code>agent._invoke('Hello world!')\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=Hello! How can I assist you today?, tool_calls=[])\n</code></pre> <p>If the LLM \"decides\" that the user needs to execute a tool, it returns a tool call as the response instead of returning content.</p> <pre><code>result = agent._invoke('Check my messages.')\nresult\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=, tool_calls=[ToolCallInfo(id='call_D0WyCNzn8Hg0qRxsui24aZ33', name='check_new_messages', type='tool_call', args={}, tool=StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x1084516c0&gt;))])\n</code></pre> <p>The tool call information can be accessed through the <code>ChatResult.tool_calls</code> attribute, which is simply a list supertype. Use <code>tool_info_str</code> to clearly show the arguments being passed to the function.</p> <pre><code>for tc in result.tool_calls:\n    print(tc.tool_info_str())\n</code></pre> <p>stdout:</p> <pre><code>check_new_messages()\n</code></pre> <p>You may also provide additional tools at the time of invoking the LLM, and it will be treated as if it was part of the chatbot. </p> <p>In this example, we create a new tool with two arguments that must be provided by the LLM.</p> <pre><code>@langchain_core.tools.tool\ndef send_message(recipient: str, text: str) -&gt; str:\n    '''Send messages to others.'''\n    return f'Message sent!'\n\nresult = agent._invoke('Send a message to Bob saying \"Hello!\"', tools=[send_message])\nresult\n</code></pre> <p>text:</p> <pre><code>ChatResult(content=, tool_calls=[ToolCallInfo(id='call_CaZgudgmby8bQahiyL2PnP6J', name='send_message', type='tool_call', args={'recipient': 'Bob', 'text': 'Hello!'}, tool=StructuredTool(name='send_message', description='Send messages to others.', args_schema=&lt;class 'langchain_core.utils.pydantic.send_message'&gt;, func=&lt;function send_message at 0x10cd45a80&gt;))])\n</code></pre> <p>You can see that the LLM provided the <code>recipient</code> and <code>text</code> arguments which were passed to the function call information.</p> <pre><code>result.tool_calls[0].tool_info_str()\n</code></pre> <p>text:</p> <pre><code>'send_message(recipient=Bob, text=Hello!)'\n</code></pre> <p>You can adjust behavior using the <code>tool_choice</code> argument in the chatbot constructor or at invokation. The value <code>'any'</code> means that a tool MUST be called, but all tools are candidates. The value <code>'auto'</code> (the default) allows the LLM to reply with normal content rather than a tool call, and you can also pass the name of a specific function as well.</p> <pre><code>result = agent._invoke('Go to the store for me!', tool_choice='any')\nresult.tool_calls[0].tool_info_str()\n</code></pre> <p>text:</p> <pre><code>'check_new_messages()'\n</code></pre>"},{"location":"examples/d-tool_calling/#executing-tools","title":"Executing Tools","text":"<p>Tools allow the LLM to determine if and when to execute tools and also provides parameters for the tool call based on conversation history, but the user containing function is responsible for actually executing the tool with the arguments from the LLM.</p> <p>Use the <code>execute_tools</code> method to actually execute the tool, which returns a mapping of tool names to <code>ToolCallResult</code> objects.</p> <pre><code>result = agent._invoke('Check my messages.')\nresult.tool_calls[0].tool_info_str()\n</code></pre> <p>text:</p> <pre><code>'check_new_messages()'\n</code></pre> <pre><code>tr = result.execute_tools()\ntr\n</code></pre> <p>text:</p> <pre><code>{'check_new_messages': ToolCallResult(info=ToolCallInfo(id='call_CPyijbPQpk91FIdl0B8NOLmI', name='check_new_messages', type='tool_call', args={}, tool=StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x1084516c0&gt;)), return_value='No new messages.')}\n</code></pre> <p>Get the return value from the tool through the <code>return_value</code> property.</p> <pre><code>tr['check_new_messages'].return_value\n</code></pre> <p>text:</p> <pre><code>'No new messages.'\n</code></pre> <p>Extracting tool calls from a <code>StreamResult</code> is a little more complicated because the stream must be exhausted before executing tools. This happens because the tool call information replaces the text response, so the streamer is essentially receiving chunks of the function call information until exhaustion.</p> <p>The calling function must handle both the streamed output and tool calls.</p> <pre><code>stream = agent._stream('Check my messages.')\nfor r in stream:\n    print(r, end='', flush=True)\nif len(stream.tool_calls) &gt; 0:\n    stream.execute_tools()\n</code></pre> <p>stdout:</p> <pre><code>content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_0I3oV4MeoavXZe8gyJygHkQZ', 'function': {'arguments': '', 'name': 'check_new_messages'}, 'type': 'function'}]} response_metadata={} id='run-029ed68d-e9ad-4a1f-9716-960302d7c64b' tool_calls=[{'name': 'check_new_messages', 'args': {}, 'id': 'call_0I3oV4MeoavXZe8gyJygHkQZ', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'check_new_messages', 'args': '', 'id': 'call_0I3oV4MeoavXZe8gyJygHkQZ', 'index': 0, 'type': 'tool_call_chunk'}]content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': None, 'function': {'arguments': '{}', 'name': None}, 'type': None}]} response_metadata={} id='run-029ed68d-e9ad-4a1f-9716-960302d7c64b' tool_calls=[{'name': '', 'args': {}, 'id': None, 'type': 'tool_call'}] tool_call_chunks=[{'name': None, 'args': '{}', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]content='' additional_kwargs={} response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306'} id='run-029ed68d-e9ad-4a1f-9716-960302d7c64b'\n</code></pre> <p>A <code>ValueError</code> will be raised if the caller tries to execute tools before the stream is exhausted.</p> <pre><code>stream = agent.stream('Check my messages.')\nfor r in stream:\n    print(r.content, end='', flush=True)\n    break\ntry:\n    stream.execute_tools()\nexcept ValueError as e:\n    print('Exception was caught!')\n</code></pre> <p>stdout:</p> <pre><code>Exception was caught!\n</code></pre>"},{"location":"examples/d-tool_calling/#toolkits-and-tool-factories","title":"Toolkits and Tool Factories","text":"<p>Aside from providing a list of tools, you may also bind tools from toolkits and tool factories.</p> <ul> <li> <p><code>ToolKit</code>: class with a <code>get_tools() -&gt; list[BaseTool]</code> method. <code>ToolKit</code>s are part of the langchain interface, and the built-in tools often come as a subtype. Passed through the <code>toolkits: list[BaseToolkit]</code> argument.</p> </li> <li> <p>Tool Factories: functions that accept a chatbot as an argument and return tools. Useful when writing tools that interact with the original LLM because otherwise it would require partial initialization. Passed through the <code>tool_factories: ToolFactoryType</code> argument.</p> </li> </ul> <p>Note that these too may be provided at instantiation or at invokation.</p>"},{"location":"examples/d-tool_calling/#toolkit-example","title":"<code>ToolKit</code> Example","text":"<p>In this example, I enable the built-in Langchain <code>FileManagementToolkit</code> toolkit to allow the chatbot to list, read, and write files.</p> <pre><code>import tempfile\nfrom langchain_community.agent_toolkits import FileManagementToolkit\nwith tempfile.TemporaryDirectory() as wd:\n    file_tk = FileManagementToolkit(root_dir=str(wd))\n    result = agent._invoke('List the files in this directory.', toolkits=[file_tk])\n    print(result.tool_calls[0].tool_info_str())\n</code></pre> <p>stdout:</p> <pre><code>list_directory()\n</code></pre>"},{"location":"examples/d-tool_calling/#tool-factory-examples","title":"Tool Factory Examples","text":"<p>Now I create a tool factory that can be passed to the chatbot. This tool uses the chatbot reference to invoke the LLM with access to all of the same tools.</p> <pre><code>def my_tool_factory(agent: simplechatbot.Agent) -&gt; list[langchain_core.tools.Tool]:\n    @langchain_core.tools.tool\n    def story_generator(topic: str) -&gt; str:\n        '''Generate a story absed on a particular topic.'''\n        result = agent._invoke(\n            f'Generate a story about {topic}. Your response should only include the text of the story and make it short but engaging.',\n        )\n        return result.content\n\n    return [story_generator]\n\nresult = agent._invoke('Generate a story about western cowboys.', tool_factories=[my_tool_factory])\ntc_result = result.execute_tools()\ntc_result['story_generator'].return_value\n</code></pre> <p>text:</p> <pre><code>'In the heart of the rugged Wild West, a small town called Dusty Springs thrived under the watchful eyes of the surrounding mesas. The sun blazed overhead, casting long shadows over the dusty streets where only a handful of souls dared to tread. Among them was Colt Harper, a seasoned cowboy known for his swift draw and uncanny ability to ride like the wind.\\n\\nOne sweltering afternoon, a mysterious stranger rode into town on a sleek black stallion. Cloaked in a dust-covered duster and a wide-brimmed hat that obscured his face, he dismounted at the saloon, causing the townsfolk to whisper in hushed tones. Colt, nursing a whiskey at the bar, felt a stirring in his gut; trouble had a way of finding him.\\n\\nThe stranger, known only as Jake, challenged Colt to a duel at high noon. Rumors swirled that Jake was looking for revenge against Colt\u2019s brother, who had long since met his fate in a gunfight gone wrong. As the clock ticked towards noon, the townspeople gathered, tension crackling in the air like a summer storm.\\n\\nColt strode into the street, his boots kicking up dust as he faced Jake under the blazing sun. The world around them faded away, each heartbeat echoing in the silence. With a quick draw, Colt aimed and fired, the bullet whistling through the air and finding its mark. Jake fell, surprise blossoming on his face, and the whispering crowd gasped.\\n\\nAs the dust settled, Colt walked over to him. \u201cThis ain\u2019t no way to settle a score,\u201d he said, his voice steady. \u201cLet\u2019s put the past to rest. Life\u2019s too short.\u201d Jake nodded slowly, his anger replaced by a flicker of understanding.\\n\\nThe two men stood, embodying a spirit of camaraderie that echoed through the rugged landscape. Dusty Springs would remember that day not just for the gunfight, but for the moment a cowboy chose peace over vengeance. As the sun dipped below the horizon, Colt tipped his hat and rode off into the golden glow, a true gunslinger of the West.'\n</code></pre>"},{"location":"examples/d-tool_calling/#conclusions","title":"Conclusions","text":"<p>That is all! Now you know how to enable and disable tools that your LLM can use to do anything!</p>"},{"location":"examples/f-multi-agent_example/","title":"Multi-agent Examples","text":"<p>In this example I show an example of an agent that writes a story using a series of steps.</p> <ol> <li>The user provides an idea for their story.</li> <li>The <code>Outline Bot</code> generates an outline for the story including section titles and descriptions.</li> <li>The first section content is created by the <code>Story Bot</code> from section title/description and the overall story description.</li> <li>The <code>Summary Bot</code> creates a summary of the newly generated chapter.</li> <li>The section summary is passed to the <code>Story Bot</code> along with section title/description to generate the next section.</li> <li>All sections follow steps 3-5. ...</li> <li>The sections are combined into a full story.</li> </ol> <p></p> <pre><code>import pydantic\nimport typing\n\nimport sys\nsys.path.append('../src/')\n\nimport simplechatbot\nfrom simplechatbot.openai_agent import OpenAIAgent\n</code></pre> <p>First I create a new chatbot from OpenAI using the API stored in the keychain file.</p> <p>I also create a new function <code>stream_it</code> that prints the result from the LLM as it is received and returns the full result of the LLM call.</p> <pre><code>keychain = simplechatbot.APIKeyChain.from_json_file('../keys.json')\nbase_agent = OpenAIAgent.new(\n    model_name = 'gpt-4o-mini', \n    api_key=keychain['openai'],\n)\n</code></pre> <p>Next we need to direct the LLM to create an outline for the story. I do this by creating a system prompt describing the task of creating an outline and a pydantic class to direct the LLM on how to structure its response. This is important because the output of the outline bot will be used for generating chapters.</p> <pre><code>class StoryOutline(pydantic.BaseModel):\n    \"\"\"Outline of the story.\"\"\"\n\n    story_topic: str = pydantic.Field(description=\"The topic of the story.\")\n\n    part1_title: str = pydantic.Field(description=\"Title of Part 1 of the story.\")\n    part1_description: str = pydantic.Field(description=\"Longer description of part 1.\")\n\n    part2_title: str = pydantic.Field(description=\"Title of Part 2 of the story.\")\n    part2_description: str = pydantic.Field(description=\"Longer description of part 2.\")\n\n    part3_title: str = pydantic.Field(description=\"Title of Part 3 of the story.\")\n    part3_description: str = pydantic.Field(description=\"Longer description of part 3.\")\n\n    def outline_str(self) -&gt; str:\n        return f'topic: {self.story_topic}\\n\\n{self.part1_title}: {self.part1_description}\\n\\n{self.part2_title}: {self.part2_description}\\n\\n{self.part3_title}: {self.part3_description}'\n\n\nclass OutlineBot:\n    system_prompt = (\n        \"The user will provide you a description of a story, and you must create a chapter outline with titles and brief descriptions. \"\n        \"Each section should contain a title and a brief description of what happens in that section. \"\n        \"The sections should all be part of a single narrative ark, but each section should have a complete beginning, middle, and end. \"\n    )\n    def __init__(self, base_agent: simplechatbot.Agent):\n        self.agent = base_agent.new_agent_from_model(\n            system_prompt=self.system_prompt,\n        )\n\n    def create_outline(self, story_description: str) -&gt; StoryOutline:\n        return self.agent.chat_structured(story_description, output_structure=StoryOutline).data\n\noutline_bot = OutlineBot(base_agent)\n\nq = f'Write an outline for a story about two friends who met when they were young and then lost touch. They meet again as adults and have to navigate their new relationship.'\noutline: StoryOutline = outline_bot.create_outline(q)\nprint(outline.outline_str())\n</code></pre> <p>stdout:</p> <pre><code>topic: Rekindling a Friendship\n\nThe Innocent Bond: In a small town, two children, Mia and Jake, form a deep bond during summer vacations. They share adventures, secrets, and dreams, making a pact to always stay friends. However, as they grow older, Mia moves away, and they lose touch. The chapter ends with Mia looking back at old photos, reminiscing about the carefree days of their friendship and wondering how Jake is doing.\n\nA Chance Encounter: Years later, Mia returns to her hometown for a wedding. On the night of the event, she unexpectedly runs into Jake, who hasn't changed much but feels like a stranger. Their initial conversation is awkward, filled with nostalgia and uncertainty. But as the night unfolds, they find common ground in shared memories. They agree to grab coffee the next day to catch up, both feeling a mix of excitement and anxiety about seeing each other after so long.\n\nRebuilding the Past: During coffee, Mia and Jake navigate the complexities of their adult lives, revealing new aspects of their personalities that have developed separately. They reminisce about the past but also confront the differences that have emerged over the years. Misunderstandings arise but are resolved through open communication, leading to a rekindling of their friendship. The chapter ends with both feeling hopeful but uncertain about what the future holds for their relationship.\n</code></pre> <p>Next we create a bot that will generate the actual chapter content based on information generated in the outline and a summary of the previous chapter (if one exists).</p> <pre><code>class ChapterBot:\n    system_prompt = (\n        \"You are designed to write a single chapter of a larger story based on the following information: \\n\\n\"\n        \"+ Overall story topic: The topic of the full story.\\n\"\n        \"+ Chapter title: The title of the section you are writing.\\n\"\n        \"+ Chapter description: A longer description of what happens in the section.\\n\"\n        \"+ (optional) previous chapter summary: A summary of the previous chapter.\\n\"\n        \"Your responses should only include text that is part of the story. Do not include the chapter title \\n\"\n        \"or any other information that is not part of the story itself.\\n\"\n        \"The story chapter should be super short, so keep that in mind!\"\n    )\n\n    def __init__(self, base_agent: simplechatbot.Agent):\n        self.agent = base_agent.new_agent_from_model(\n            system_prompt=self.system_prompt,\n        )\n\n    def write_chapter(\n        self,\n        story_topic: str,\n        chapter_title: str,\n        chapter_description: str,\n        previous_chapter_summary: typing.Optional[str] = None,\n    ) -&gt; str:\n        prompt = (\n            f'General story topic: \"{story_topic}\"\\n\\n'\n            f'Section title: \"{chapter_title}\"\\n\\n'\n            f'Description: \"{chapter_description}\"\\n\\n'\n            f'Previous chapter summary: \"{previous_chapter_summary if previous_chapter_summary is not None else \"No previous chapter - this is the first!\"}\"'\n        )\n        return self.agent.stream(prompt, add_to_history=False).print_and_collect().content\n\nchapter_bot = ChapterBot(base_agent)\n</code></pre> <p>Now we actually create the chatper using the prompt.</p> <pre><code>chapter1 = chapter_bot.write_chapter(outline.story_topic, outline.part1_title, outline.part1_description)\n</code></pre> <p>stdout:</p> <pre><code>The sun-drenched days of summer blended into a tapestry of laughter and adventure for Mia and Jake. Their small town, a canvas of vibrant colors and warm breezes, became the backdrop for their blossoming friendship.\n\nThey often met at the old oak tree, its branches spreading wide like welcoming arms, where they shared whispered secrets and dreams of the future. One day, they painstakingly crafted a treasure map from an old cereal box, declaring their mission to find hidden gems in the nearby woods. With their imaginations running wild, they transformed fallen twigs into swords, prowled like pirates, and crowned each other as guardians of their secret world.\n\nMia would sometimes pull out her worn notebook, filled with sketches of their adventures, while Jake would recount tales of daring knights and fearless dragons. They made a pact\u2014an earnest promise to always stay friends\u2014each believing their bond was unbreakable.\n\nThen, as summer slipped away and the cold winds of fate began to blow, Mia's family received the news. They were moving, a change that echoed with uncertainty and sadness. On the night before her departure, they sat under the stars, their hearts heavy with unspoken fears. Mia held Jake's hand tightly, sealing their pact with a desperate wish that distance would never come between them.\n\nYears passed like fluttering leaves in the autumn breeze. Mia moved to a place where everything felt foreign. New friends filled her days, but the whispers of that innocent bond lingered in the corners of her heart. One quiet evening, feeling nostalgic, she rummaged through a box of memories.\n\nAs she pulled out old photographs, the vibrant summer days unfolded before her eyes. There they were, sunlight dancing off their smiles, the world their playground. She paused at a picture where they both grinned widely, remnants of mud smeared on their cheeks from a day spent crafting makeshift capes in the backyard, imaginations soaring.\n\nMia\u2019s heart tightened as she wondered where Jake was now, if he recalled their pact, the whispers of their carefree laughter carried by the winds through the years. In that moment, she realized that though miles apart, the bond they forged during those innocent days still held a spark of hope, waiting to be rekindled.\n</code></pre> <p>Next I create a bot that will summarize a chapter. We will eventually feed this into the creation of chapter 2.</p> <pre><code>class SummaryBot:\n    system_prompt = (\n        'You need to create a summary of the story chapter provided to you by the user. '\n        'The summary should include names of relevant characters and capture the story arc of the chapter. '\n    )\n\n    def __init__(self, base_agent: simplechatbot.Agent):\n        self.agent = base_agent.new_agent_from_model(\n            system_prompt=self.system_prompt,\n        )\n\n    def summarize(\n        self,\n        chapter_text: str,\n    ) -&gt; str:\n        prompt = (\n            f'Chapter text:\\n\\n{chapter_text}'\n        )\n        return self.agent.stream(prompt, add_to_history=False).print_and_collect().content\n\nsummary_bot = SummaryBot(base_agent)\n</code></pre> <pre><code>ch1_summary = summary_bot.summarize(chapter1)\n</code></pre> <p>stdout:</p> <pre><code>In this poignant chapter, we follow Mia and Jake, two friends who share a magical summer filled with adventures in their small town. Their friendship flourishes at the old oak tree, where they craft a treasure map and transform their imaginations into a world of pirates, knights, and dreams. They create a pact to always remain friends, believing their bond is unbreakable.\n\nHowever, their idyllic summer comes to an abrupt end when Mia's family announces they are moving away, leading to a heart-wrenching farewell under the starlit sky. Mia and Jake hold hands tightly, each silently wishing that distance would not diminish their friendship.\n\nAs the years progress, Mia finds herself in a new, foreign place, making new friends but often reminiscing about her time with Jake. One evening, she discovers a box of memories, pulling out old photographs that remind her of their joyful days together. Reflecting on their shared adventures and the special bond they created, Mia wonders if Jake still remembers their pact. The chapter concludes with a sense of nostalgia and hope, highlighting that despite the miles between them, the spark of their friendship still glows, waiting for a chance to reignite.\n</code></pre> <p>Now we actually generate the second chapter using the outline and the previous chapter summary.</p> <pre><code>chapter2 = chapter_bot.write_chapter(outline.story_topic, outline.part2_title, outline.part2_description, ch1_summary)\n</code></pre> <p>stdout:</p> <pre><code>Mia stepped out of the wedding venue, the soft glow of string lights illuminating the night as laughter and music floated through the air. She wrapped her shawl tighter around her shoulders, feeling a chill that had nothing to do with the evening breeze. It was a night of joy, yet a weight settled in her chest as she navigated the familiar streets of her hometown.\n\nSuddenly, she spotted him across the courtyard \u2013 Jake, leaning casually against a pillar, his tall frame and easy smile still as comforting as she remembered. The years melted into the background as their eyes locked, and it felt as if time had rewound to that summer when everything was simple. But beneath the familiarity lay an awkwardness; he was a stranger now, the miles between them stretching wider than she\u2019d anticipated.\n\n\u201cJake?\u201d Mia called out, her voice barely cutting through the thrum of the festivities.\n\n\u201cMia!\u201d he responded, his surprise mirrored in his bright eyes. He stepped forward, hands shoved in his pockets. \u201cWow, it\u2019s been\u2026 what? Nearly a decade?\u201d\n\n\u201cYeah, something like that.\u201d She chuckled nervously, glancing away. \u201cYou look\u2026 well, the same.\u201d\n\nHe laughed, a sound that tugged at her heart, but it felt different this time \u2014 tinged with a hint of uncertainty. \u201cAnd you still have that same spark,\u201d he replied, though just as quickly as the words left his mouth, his expression faltered. \u201cHow\u2019s life been?\u201d\n\nThey each began to share snippets of their lives, awkward pauses punctuating their conversation. The nostalgia laced their exchanges, memories of childhood adventures swirling around them. \u201cDo you remember that treasure map we made?\u201d Mia asked, a smile creeping onto her face.\n\nJake\u2019s face lit up. \u201cOf course. We thought we were real pirates.\u201d\n\nThe moment drew them closer, their shared laughter echoing in the night. As they reminisced, the tension melted away, and a flicker of connection sparked anew. Their hearts raced with an unspoken agreement: they wouldn\u2019t let this chance pass by.\n\n\u201cHow about we grab coffee tomorrow?\u201d Mia suggested, holding her breath as she waited for his response.\n\n\u201cYeah, I\u2019d like that,\u201d Jake replied, his smile returning with a hint of warmth.\n\nAs they parted ways, a mix of excitement and anxiety washed over Mia. She watched him walk back into the crowd, feeling a renewed sense of hope. Perhaps this was the beginning of rekindling what they had lost, a chance to mend the spaces that distance had created.\n</code></pre> <p>Create a summary for chapter 2 now.</p> <pre><code>ch2_summary = summary_bot.summarize(chapter2)\n</code></pre> <p>stdout:</p> <pre><code>In this chapter, Mia finds herself stepping out of a wedding venue, overwhelmed by a mix of joy and nostalgia. As she walks through her hometown, she unexpectedly encounters Jake, her childhood friend and first love, who she hasn't seen in nearly a decade. Their initial interaction is filled with awkwardness and familiarity, highlighting the emotional distance that time and circumstances have created between them.\n\nThey engage in small talk, reminiscing about their childhood adventures, such as creating a treasure map, which leads to laughter and a rekindling of their connection. Despite the years apart, they quickly find common ground, indicating an enduring bond beneath the surface. As Mia suggests meeting for coffee the next day, both characters sense a hopeful opportunity to explore what could be a revival of their relationship. The chapter concludes with Mia feeling a renewed sense of hope for the future as she watches Jake disappear back into the crowd, hinting at the possibility of mending the gaps that time had widened between them.\n</code></pre> <p>Use the summary of chapter 2 and outline information to create chapter 3.</p> <pre><code>chapter3 = chapter_bot.write_chapter(outline.story_topic, outline.part3_title, outline.part3_description, ch2_summary)\n</code></pre> <p>stdout:</p> <pre><code>The coffee shop smelled of roasted beans and sweet pastries, a familiar scent that enveloped Mia as she entered, her heart racing with anticipation. She spotted Jake at a corner table, his back straight, absorbed in a steaming mug. Memories flooded her as she approached\u2014of painting their childhood treehouse and sharing secrets under the stars.\n\n\u201cHey,\u201d she said, her voice barely above a whisper.\n\nHe looked up, his expression brightening. \u201cHey, you made it.\u201d\n\nThey exchanged warm smiles, feeling the shock of re-encounter fade, replaced by a comfortable, yet cautious atmosphere. As they sipped their coffees, the conversation flowed from light-hearted banter to deeper confessions. Mia shared tales of her career struggles, and Jake spoke of unpredictable travel adventures.\n\n\u201cRemember the treasure map we made?\u201d Mia chuckled, attempting to bridge any lingering gaps, her fingers tracing the rim of her cup.\n\nJake laughed, a sound that reminded her of so many summers spent laughing together. \u201cYeah, and how we never found anything but those old coins?\u201d\n\nA moment of silence lingered as they both realized how their paths have diverged since those days\u2014her commitment to a steady job, his penchant for spontaneity. Tension arose as they stumbled into differences: Jake\u2019s love for risk clashed with Mia\u2019s yearning for stability.\n\n\u201cThis is nice, but\u2026\u201d Mia hesitated, searching for the right words, \u201ccould we talk about how life has changed us?\u201d\n\nHe nodded, looking serious for a moment. Misunderstandings emerged as they aired out old grievances\u2014miscommunication that had haunted their friendship for years.\n\n\u201cI thought you were mad at me for leaving,\u201d Jake admitted, running a hand through his hair.\n\n\u201cI was just scared of losing you,\u201d Mia replied, her voice trembling slightly. They both took deep breaths, the tension easing as honesty laid the groundwork for rebuilding.\n\nWith each revelation, walls crumbled, revealing the roots of their companionship buried beneath soil and time. They embraced vulnerability, each apology serving as both an acknowledgment of the past and a guide forward.\n\nThey left the coffee shop with that same hopeful feeling\u2014a cautious optimism decorating the edges of their hearts. As Mia turned to look at Jake one last time before parting ways, a sense of uncertainty lingered in the air. Would this be the beginning of something new, or merely a fleeting spark?\n</code></pre> <p>And now we can review the full text of the book.</p> <pre><code>story = f'''\n\nOverview: {outline.story_topic}\n\n== Chapter 1: {outline.part1_title} ==\n\n{chapter1}\n\n\n== Chapter 2: {outline.part2_title} ==\n\n{chapter2}\n\n\n== Chapter 3: {outline.part3_title} ==\n\n{chapter3}\n\n'''\n\nimport pprint\npprint.pprint(story)\n</code></pre> <p>stdout:</p> <pre><code>('\\n'\n '\\n'\n 'Overview: Rekindling a Friendship\\n'\n '\\n'\n '== Chapter 1: The Innocent Bond ==\\n'\n '\\n'\n 'The sun-drenched days of summer blended into a tapestry of laughter and '\n 'adventure for Mia and Jake. Their small town, a canvas of vibrant colors and '\n 'warm breezes, became the backdrop for their blossoming friendship. \\n'\n '\\n'\n 'They often met at the old oak tree, its branches spreading wide like '\n 'welcoming arms, where they shared whispered secrets and dreams of the '\n 'future. One day, they painstakingly crafted a treasure map from an old '\n 'cereal box, declaring their mission to find hidden gems in the nearby woods. '\n 'With their imaginations running wild, they transformed fallen twigs into '\n 'swords, prowled like pirates, and crowned each other as guardians of their '\n 'secret world. \\n'\n '\\n'\n 'Mia would sometimes pull out her worn notebook, filled with sketches of '\n 'their adventures, while Jake would recount tales of daring knights and '\n 'fearless dragons. They made a pact\u2014an earnest promise to always stay '\n 'friends\u2014each believing their bond was unbreakable.\\n'\n '\\n'\n \"Then, as summer slipped away and the cold winds of fate began to blow, Mia's \"\n 'family received the news. They were moving, a change that echoed with '\n 'uncertainty and sadness. On the night before her departure, they sat under '\n \"the stars, their hearts heavy with unspoken fears. Mia held Jake's hand \"\n 'tightly, sealing their pact with a desperate wish that distance would never '\n 'come between them.\\n'\n '\\n'\n 'Years passed like fluttering leaves in the autumn breeze. Mia moved to a '\n 'place where everything felt foreign. New friends filled her days, but the '\n 'whispers of that innocent bond lingered in the corners of her heart. One '\n 'quiet evening, feeling nostalgic, she rummaged through a box of memories. \\n'\n '\\n'\n 'As she pulled out old photographs, the vibrant summer days unfolded before '\n 'her eyes. There they were, sunlight dancing off their smiles, the world '\n 'their playground. She paused at a picture where they both grinned widely, '\n 'remnants of mud smeared on their cheeks from a day spent crafting makeshift '\n 'capes in the backyard, imaginations soaring.\\n'\n '\\n'\n 'Mia\u2019s heart tightened as she wondered where Jake was now, if he recalled '\n 'their pact, the whispers of their carefree laughter carried by the winds '\n 'through the years. In that moment, she realized that though miles apart, the '\n 'bond they forged during those innocent days still held a spark of hope, '\n 'waiting to be rekindled.\\n'\n '\\n'\n '\\n'\n '== Chapter 2: A Chance Encounter ==\\n'\n '\\n'\n 'Mia stepped out of the wedding venue, the soft glow of string lights '\n 'illuminating the night as laughter and music floated through the air. She '\n 'wrapped her shawl tighter around her shoulders, feeling a chill that had '\n 'nothing to do with the evening breeze. It was a night of joy, yet a weight '\n 'settled in her chest as she navigated the familiar streets of her '\n 'hometown. \\n'\n '\\n'\n 'Suddenly, she spotted him across the courtyard \u2013 Jake, leaning casually '\n 'against a pillar, his tall frame and easy smile still as comforting as she '\n 'remembered. The years melted into the background as their eyes locked, and '\n 'it felt as if time had rewound to that summer when everything was simple. '\n 'But beneath the familiarity lay an awkwardness; he was a stranger now, the '\n 'miles between them stretching wider than she\u2019d anticipated. \\n'\n '\\n'\n '\u201cJake?\u201d Mia called out, her voice barely cutting through the thrum of the '\n 'festivities. \\n'\n '\\n'\n '\u201cMia!\u201d he responded, his surprise mirrored in his bright eyes. He stepped '\n 'forward, hands shoved in his pockets. \u201cWow, it\u2019s been\u2026 what? Nearly a '\n 'decade?\u201d\\n'\n '\\n'\n '\u201cYeah, something like that.\u201d She chuckled nervously, glancing away. \u201cYou '\n 'look\u2026 well, the same.\u201d\\n'\n '\\n'\n 'He laughed, a sound that tugged at her heart, but it felt different this '\n 'time \u2014 tinged with a hint of uncertainty. \u201cAnd you still have that same '\n 'spark,\u201d he replied, though just as quickly as the words left his mouth, his '\n 'expression faltered. \u201cHow\u2019s life been?\u201d\\n'\n '\\n'\n 'They each began to share snippets of their lives, awkward pauses punctuating '\n 'their conversation. The nostalgia laced their exchanges, memories of '\n 'childhood adventures swirling around them. \u201cDo you remember that treasure '\n 'map we made?\u201d Mia asked, a smile creeping onto her face.\\n'\n '\\n'\n 'Jake\u2019s face lit up. \u201cOf course. We thought we were real pirates.\u201d \\n'\n '\\n'\n 'The moment drew them closer, their shared laughter echoing in the night. As '\n 'they reminisced, the tension melted away, and a flicker of connection '\n 'sparked anew. Their hearts raced with an unspoken agreement: they wouldn\u2019t '\n 'let this chance pass by. \\n'\n '\\n'\n '\u201cHow about we grab coffee tomorrow?\u201d Mia suggested, holding her breath as '\n 'she waited for his response.\\n'\n '\\n'\n '\u201cYeah, I\u2019d like that,\u201d Jake replied, his smile returning with a hint of '\n 'warmth. \\n'\n '\\n'\n 'As they parted ways, a mix of excitement and anxiety washed over Mia. She '\n 'watched him walk back into the crowd, feeling a renewed sense of hope. '\n 'Perhaps this was the beginning of rekindling what they had lost, a chance to '\n 'mend the spaces that distance had created.\\n'\n '\\n'\n '\\n'\n '== Chapter 3: Rebuilding the Past ==\\n'\n '\\n'\n 'The coffee shop smelled of roasted beans and sweet pastries, a familiar '\n 'scent that enveloped Mia as she entered, her heart racing with anticipation. '\n 'She spotted Jake at a corner table, his back straight, absorbed in a '\n 'steaming mug. Memories flooded her as she approached\u2014of painting their '\n 'childhood treehouse and sharing secrets under the stars.\\n'\n '\\n'\n '\u201cHey,\u201d she said, her voice barely above a whisper. \\n'\n '\\n'\n 'He looked up, his expression brightening. \u201cHey, you made it.\u201d\\n'\n '\\n'\n 'They exchanged warm smiles, feeling the shock of re-encounter fade, replaced '\n 'by a comfortable, yet cautious atmosphere. As they sipped their coffees, the '\n 'conversation flowed from light-hearted banter to deeper confessions. Mia '\n 'shared tales of her career struggles, and Jake spoke of unpredictable travel '\n 'adventures. \\n'\n '\\n'\n '\u201cRemember the treasure map we made?\u201d Mia chuckled, attempting to bridge any '\n 'lingering gaps, her fingers tracing the rim of her cup.\\n'\n '\\n'\n 'Jake laughed, a sound that reminded her of so many summers spent laughing '\n 'together. \u201cYeah, and how we never found anything but those old coins?\u201d\\n'\n '\\n'\n 'A moment of silence lingered as they both realized how their paths have '\n 'diverged since those days\u2014her commitment to a steady job, his penchant for '\n 'spontaneity. Tension arose as they stumbled into differences: Jake\u2019s love '\n 'for risk clashed with Mia\u2019s yearning for stability.\\n'\n '\\n'\n '\u201cThis is nice, but\u2026\u201d Mia hesitated, searching for the right words, \u201ccould we '\n 'talk about how life has changed us?\u201d\\n'\n '\\n'\n 'He nodded, looking serious for a moment. Misunderstandings emerged as they '\n 'aired out old grievances\u2014miscommunication that had haunted their friendship '\n 'for years.\\n'\n '\\n'\n '\u201cI thought you were mad at me for leaving,\u201d Jake admitted, running a hand '\n 'through his hair.\\n'\n '\\n'\n '\u201cI was just scared of losing you,\u201d Mia replied, her voice trembling '\n 'slightly. They both took deep breaths, the tension easing as honesty laid '\n 'the groundwork for rebuilding.\\n'\n '\\n'\n 'With each revelation, walls crumbled, revealing the roots of their '\n 'companionship buried beneath soil and time. They embraced vulnerability, '\n 'each apology serving as both an acknowledgment of the past and a guide '\n 'forward.\\n'\n '\\n'\n 'They left the coffee shop with that same hopeful feeling\u2014a cautious optimism '\n 'decorating the edges of their hearts. As Mia turned to look at Jake one last '\n 'time before parting ways, a sense of uncertainty lingered in the air. Would '\n 'this be the beginning of something new, or merely a fleeting spark?\\n'\n '\\n')\n</code></pre>"}]}