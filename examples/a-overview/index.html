
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://devincornell.github.io/simplechatbot/examples/a-overview/">
      
      
        <link rel="prev" href="../..">
      
      
        <link rel="next" href="../b-tool_calling/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.39">
    
    
      
        <title>Introduction - simplechatbot</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8c3ca2c6.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduction" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="simplechatbot" class="md-header__button md-logo" aria-label="simplechatbot" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            simplechatbot
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Introduction
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/devincornell/simplechatbot" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    devincornell/simplechatbot
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="simplechatbot" class="md-nav__button md-logo" aria-label="simplechatbot" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    simplechatbot
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/devincornell/simplechatbot" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    devincornell/simplechatbot
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#instantiating-chatbot-objects" class="md-nav__link">
    <span class="md-ellipsis">
      Instantiating ChatBot Objects
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#high-level-chat-and-chat_stream-methods" class="md-nav__link">
    <span class="md-ellipsis">
      High-level chat and chat_stream Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="High-level chat and chat_stream Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#chat-and-chatresult-objects" class="md-nav__link">
    <span class="md-ellipsis">
      .chat() and ChatResult Objects
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chat_stream-and-streamresult-objects" class="md-nav__link">
    <span class="md-ellipsis">
      .chat_stream() and StreamResult Objects
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#low-level-llm-methods-invoke-and-stream" class="md-nav__link">
    <span class="md-ellipsis">
      Low-level LLM Methods: invoke and stream
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chat-user-interface" class="md-nav__link">
    <span class="md-ellipsis">
      Chat User Interface
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../b-tool_calling/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tool Calling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../c-model_specific_chatbots/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model-specific ChatBots
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#instantiating-chatbot-objects" class="md-nav__link">
    <span class="md-ellipsis">
      Instantiating ChatBot Objects
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#high-level-chat-and-chat_stream-methods" class="md-nav__link">
    <span class="md-ellipsis">
      High-level chat and chat_stream Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="High-level chat and chat_stream Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#chat-and-chatresult-objects" class="md-nav__link">
    <span class="md-ellipsis">
      .chat() and ChatResult Objects
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chat_stream-and-streamresult-objects" class="md-nav__link">
    <span class="md-ellipsis">
      .chat_stream() and StreamResult Objects
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#low-level-llm-methods-invoke-and-stream" class="md-nav__link">
    <span class="md-ellipsis">
      Low-level LLM Methods: invoke and stream
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#chat-user-interface" class="md-nav__link">
    <span class="md-ellipsis">
      Chat User Interface
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="introduction">Introduction</h1>
<p>This is a brief introduction to the <code>simplechatbot</code> package.</p>
<pre><code class="language-python">import sys
sys.path.append('..')

import simplechatbot
</code></pre>
<h2 id="instantiating-chatbot-objects">Instantiating <code>ChatBot</code> Objects</h2>
<p><code>ChatBot</code> instances maintain three elements: a chat model (or runnable) LLM, chat history, and available tools / functions.</p>
<p>It may be instantiated from any <a href="https://python.langchain.com/v0.1/docs/modules/model_io/chat/">langchain chat model</a> or runnable.</p>
<pre><code class="language-python">from langchain_openai import ChatOpenAI

# optional: use this to grab keys from a json file rather than setting system variables
keychain = simplechatbot.APIKeyChain.from_json_file('../keys.json')

openai_model = ChatOpenAI(model='gpt-4o-mini', api_key=keychain['openai'])
chatbot = simplechatbot.ChatBot.from_model(model=openai_model)
print(chatbot)
</code></pre>
<pre><code>ChatBot(model_type=ChatOpenAI, model_name="gpt-4o-mini", tools=None)
</code></pre>
<p>The <code>tools</code> parameter allows you to pass any <a href="https://python.langchain.com/v0.1/docs/modules/tools/">langchain tools</a> you want your chatbot to be able to use. You can use one of <a href="https://python.langchain.com/v0.1/docs/integrations/tools/">Langchain's built-in tools</a> (such as <code>FileManagementToolkit</code>) or <a href="https://python.langchain.com/v0.1/docs/modules/tools/custom_tools/">define your own custom tools</a>. I will use <code>FileManagementToolkit</code> for demonstration purposes here.</p>
<pre><code class="language-python">import langchain_core.tools

@langchain_core.tools.tool
def check_new_messages(text: str, username: str) -&gt; str:
    '''Check messages.'''
    return f'No new messages.'

chatbot = simplechatbot.ChatBot.from_model(
    model = openai_model,
    tools = [check_new_messages],
)
</code></pre>
<p>You can see that tools are added to an internal <code>ToolSet</code> object.</p>
<pre><code class="language-python">chatbot.toolset
</code></pre>
<pre><code>ToolSet(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x12d08f600&gt;)})
</code></pre>
<p>Set a system prompt for the chatbot by passing it as the <code>system_prompt</code> argument.</p>
<pre><code class="language-python">system_prompt = '''
You are a creative designer who has been tasked with creating a new slogan for a company.
The user will describe the company, and you will need to generate three slogan ideas for them.
'''
chatbot = simplechatbot.ChatBot.from_model(
    model = openai_model,
    tools = [check_new_messages],
    system_prompt=system_prompt,
)
</code></pre>
<p>While the LLM itself is just a function, we build conversation-like behavior by storing a chat history. In <code>simplechatbot</code>, the history is stored in a <code>ChatHistory</code>, which is just a list subtype where list elements contain langchain <code>BaseMessage</code> subtypes. You can access it through the <code>history</code> property, and work with it just as a list.</p>
<p>Here you can see that the system prompt is simply added as the first message in the chatbot history. </p>
<pre><code class="language-python">chatbot.history
</code></pre>
<pre><code>[SystemMessage(content='\nYou are a creative designer who has been tasked with creating a new slogan for a company.\nThe user will describe the company, and you will need to generate three slogan ideas for them.\n', additional_kwargs={}, response_metadata={})]
</code></pre>
<p>To see the conversation history that is sent to the LLM, you can use the <code>get_buffer_string</code> method. This uses the same langchain methods used to invoke the LLM, so it is useful for debugging.</p>
<pre><code class="language-python">print(chatbot.history.get_buffer_string())
</code></pre>
<pre><code>System: 
You are a creative designer who has been tasked with creating a new slogan for a company.
The user will describe the company, and you will need to generate three slogan ideas for them.
</code></pre>
<p>Note that history is a <code>list</code> subtype, so you can iterate through messages as you would expect.</p>
<pre><code class="language-python">for m in chatbot.history:
    print(m)
</code></pre>
<pre><code>content='\nYou are a creative designer who has been tasked with creating a new slogan for a company.\nThe user will describe the company, and you will need to generate three slogan ideas for them.\n' additional_kwargs={} response_metadata={}
</code></pre>
<h2 id="high-level-chat-and-chat_stream-methods">High-level <code>chat</code> and <code>chat_stream</code> Methods</h2>
<p>There are two primary methods used to interact with the chatbot: <code>chat</code> and <code>chat_stream</code>. </p>
<p>These are the method use-cases:</p>
<p><code>.chat()</code> → <code>ChatResult</code>: Use when you want to retrieve the full LLM response at once when it finishes.</p>
<p><code>.chat_stream()</code> → <code>ChatStream</code>: Use when you would like to show intermediary results to the user as they are received from the LLM.</p>
<pre><code class="language-python">chatbot.chat('My name is Devin.')
</code></pre>
<pre><code>ChatResult(content=Hi Devin! How can I assist you today? Are you looking to create a slogan for a specific company or project?, tool_calls=[])
</code></pre>
<pre><code class="language-python">chatbot.chat_stream('My name is Devin and I am a creative designer.')
</code></pre>
<pre><code>ChatStream(message_iter=&lt;generator object RunnableBindingBase.stream at 0x106f2d300&gt;, chatbot=ChatBot(model_type=ChatOpenAI, model_name="gpt-4o-mini", tools=['check_new_messages']), toolset=ToolSet(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x12d08f600&gt;)}), add_reply_to_history=True, full_message=AIMessageChunk(content='', additional_kwargs={}, response_metadata={}), exhausted=False)
</code></pre>
<p>Again use the <code>get_buffer_string</code> method to conveniently view the chat history.</p>
<pre><code class="language-python">print(chatbot.history.get_buffer_string())
</code></pre>
<pre><code>System: 
You are a creative designer who has been tasked with creating a new slogan for a company.
The user will describe the company, and you will need to generate three slogan ideas for them.

Human: My name is Devin.
AI: Hi Devin! How can I assist you today? Are you looking to create a slogan for a specific company or project?
Human: My name is Devin and I am a creative designer.
</code></pre>
<p>From the response to the prompt below you can see that it is maintained in the chat history because it "retains" knowledge that is given to it.</p>
<pre><code class="language-python">chatbot.chat('I have a quiz for you: what is my name?')
</code></pre>
<pre><code>ChatResult(content=Your name is Devin!, tool_calls=[])
</code></pre>
<h4 id="chat-and-chatresult-objects"><code>.chat()</code> and <code>ChatResult</code> Objects</h4>
<p>The <code>chat</code> method submits the current message and all history to the LLM and returns the reply as a <code>ChatResult</code> object.</p>
<pre><code class="language-python">chatbot.chat('Hello world.')
</code></pre>
<pre><code>ChatResult(content=Hello, Devin! How can I assist you today?, tool_calls=[])
</code></pre>
<p>If you want to submit the current chat history but do not want to add a new message, you can pass <code>None</code> as the message argument.</p>
<pre><code class="language-python">chatbot.chat(None)
</code></pre>
<pre><code>ChatResult(content=If there's anything specific you'd like to discuss or if you need help with a project, feel free to let me know!, tool_calls=[])
</code></pre>
<p>Alternatively, if you want to submit a query to the LLM but do not want to save it in the history, set <code>add_to_history = False</code>.</p>
<pre><code class="language-python">chatbot.chat('Hello world.', add_to_history=False)
</code></pre>
<pre><code>ChatResult(content=Hello again, Devin! How can I help you today?, tool_calls=[])
</code></pre>
<p><code>ChatResult</code> objects are returned from <code>chat()</code> and <code>invoke()</code> calls and include the LLM response text or tool calling information.</p>
<pre><code class="language-python">result = chatbot.chat('What is my name?')
result
</code></pre>
<pre><code>ChatResult(content=Your name is Devin!, tool_calls=[])
</code></pre>
<p>If no tool calls were requested from the LLM, you can access the response as a string through the <code>content</code> property.</p>
<pre><code class="language-python">result.content
</code></pre>
<pre><code>'Your name is Devin!'
</code></pre>
<p>If tool calls were made, the content will be empty but you can get information about any tool calls through the <code>tool_calls</code> attribute. Notice that no tool calls were requested by the LLM in the response to this query.</p>
<pre><code class="language-python">result.tool_calls
</code></pre>
<pre><code>[]
</code></pre>
<p>If there were tool calls, you can execute them using the <code>execute_tools</code> method.</p>
<pre><code class="language-python">result.execute_tools()
</code></pre>
<pre><code>{}
</code></pre>
<p>We provided the chatbot with a tool called <code>check_new_messages</code> earlier, and the LLM will request a tool call if the user requests it.</p>
<pre><code class="language-python">result = chatbot.chat('Check new messages.')
result.tool_calls
</code></pre>
<pre><code>[ToolCallInfo(id='call_zLXf8TVFZd3azJ88wuPZfB3S', name='check_new_messages', type='tool_call', args={'text': 'Check new messages.', 'username': 'devin'}, tool=StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x12d08f600&gt;))]
</code></pre>
<p>The <code>execute_tools</code> method returns a dictionary of <code>ToolCallResult</code> objects which contain the tool call information from the LLM (<code>ToolCallInfo</code>) and the return value of the tool execution.</p>
<pre><code class="language-python">tool_results = result.execute_tools()
tool_results
</code></pre>
<pre><code>{'check_new_messages': ToolCallResult(info=ToolCallInfo(id='call_zLXf8TVFZd3azJ88wuPZfB3S', name='check_new_messages', type='tool_call', args={'text': 'Check new messages.', 'username': 'devin'}, tool=StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x12d08f600&gt;)), return_value='No new messages.')}
</code></pre>
<p>Use the <code>return_value</code> attribute to access these results.</p>
<pre><code class="language-python">tool_results['check_new_messages'].return_value
</code></pre>
<pre><code>'No new messages.'
</code></pre>
<h4 id="chat_stream-and-streamresult-objects"><code>.chat_stream()</code> and <code>StreamResult</code> Objects</h4>
<p><code>chat_stream</code> is very similar to <code>chat</code>, but allows you to return content to the user as soon as the LLM produces it. The method returns a <code>StreamResult</code> object which has an iterator interface that accumulates results from the LLM while also returning incremental results.</p>
<p>In this example, I call <code>chat_stream</code> to retrieve a <code>StreamResult</code> object, which I then iterate through to retrieve and print all results.</p>
<pre><code class="language-python">stream = chatbot.chat_stream('What is my name?')
for r in stream:
    print(r.content, end='', flush=True)
stream
</code></pre>
<pre><code>Your name is Devin!




ChatStream(message_iter=&lt;generator object RunnableBindingBase.stream at 0x12ce61b70&gt;, chatbot=ChatBot(model_type=ChatOpenAI, model_name="gpt-4o-mini", tools=['check_new_messages']), toolset=ToolSet(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x12d08f600&gt;)}), add_reply_to_history=True, full_message=AIMessageChunk(content='Your name is Devin!', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47'}), exhausted=True)
</code></pre>
<p>You can check the <code>exhausted</code> flag to see if the LLM has returned all results yet.</p>
<pre><code class="language-python">stream = chatbot.chat_stream('What is my name?')
print(stream.exhausted)
for r in stream:
    print(r.content, end='', flush=True)
print(stream.exhausted)
stream
</code></pre>
<pre><code>False
Your name is Devin!True





ChatStream(message_iter=&lt;generator object RunnableBindingBase.stream at 0x12ce61f30&gt;, chatbot=ChatBot(model_type=ChatOpenAI, model_name="gpt-4o-mini", tools=['check_new_messages']), toolset=ToolSet(tools={'check_new_messages': StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x12d08f600&gt;)}), add_reply_to_history=True, full_message=AIMessageChunk(content='Your name is Devin!', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47'}), exhausted=True)
</code></pre>
<p>After retrieving all of the LLM response, you can check if any tool calls are required.</p>
<pre><code class="language-python">stream = chatbot.chat_stream('Check my messages.')
for r in stream:
    print(r.content, end='', flush=True)
stream.tool_calls
</code></pre>
<pre><code>[ToolCallInfo(id='call_RONeUxpHmfeVKHg8AHJm1LyX', name='check_new_messages', type='tool_call', args={'text': 'Check my messages.', 'username': 'devin'}, tool=StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x12d08f600&gt;))]
</code></pre>
<p>And you would similarly execute tools by calling <code>execute_tools</code>. Note that you cannot call this method if the stream has not been exhausted.</p>
<pre><code class="language-python">stream.execute_tools()
</code></pre>
<pre><code>{'check_new_messages': ToolCallResult(info=ToolCallInfo(id='call_RONeUxpHmfeVKHg8AHJm1LyX', name='check_new_messages', type='tool_call', args={'text': 'Check my messages.', 'username': 'devin'}, tool=StructuredTool(name='check_new_messages', description='Check messages.', args_schema=&lt;class 'langchain_core.utils.pydantic.check_new_messages'&gt;, func=&lt;function check_new_messages at 0x12d08f600&gt;)), return_value='No new messages.')}
</code></pre>
<p>You can use the <code>result</code> method to get a <code>ChatResult</code> object instead. If it has not retrieved all results from the LLM, it will do so before returning.</p>
<pre><code class="language-python">chatbot.chat_stream('Hello world.').result()
</code></pre>
<pre><code>ChatResult(content=Hello again, Devin! How can I assist you today?, tool_calls=[])
</code></pre>
<h2 id="low-level-llm-methods-invoke-and-stream">Low-level LLM Methods: <code>invoke</code> and <code>stream</code></h2>
<p>These lower-level <code>invoke</code> and <code>stream</code> methods are used by the <code>chat</code> and <code>chat_stream</code> methods to submit prompts to the LLM. They can allow you to interact with the LLM and tools/functions without chat history. Their signatures are very similar to high-level methods and they return the same types.</p>
<p><strong><em>NOTE</em></strong>: <em>These methods ignore the system prompt!</em></p>
<p>The low-level <code>invoke</code> method returns a <code>ChatResult</code> object with the content and tool call information.</p>
<pre><code class="language-python">result = chatbot.invoke('Hello world!')
result
</code></pre>
<pre><code>ChatResult(content=Hello! How can I assist you today?, tool_calls=[])
</code></pre>
<p>And <code>stream</code> is very similar to <code>chat_stream</code> except that it ignores chat history.</p>
<pre><code class="language-python">stream = chatbot.stream('Check messages.')
for r in stream:
    print(r.content, end='', flush=True)
stream.execute_tools()
</code></pre>
<pre><code>Please provide the text of the message and the username you want to check.




{}
</code></pre>
<h2 id="chat-user-interface">Chat User Interface</h2>
<p>Of course, what is a chatbot if you can't actually use it? To run an interactive command-line chat, use <code>.ui.start_interactive</code>.</p>
<pre><code class="language-python"># uncomment to start interactive chat
#chatbot.ui.start_interactive(stream=True, show_intro=True, show_tools=True)
</code></pre>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.expand"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.525ec568.min.js"></script>
      
    
  </body>
</html>