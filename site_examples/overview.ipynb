{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Brief overview of using ```simplechatbot``` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import simplechatbot.v4 as simplechatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ChatBot` Objects\n",
    "\n",
    "`ChatBot` instances maintain the three things that define a chatbot: a chat model (or runnable), chat history, and available tools / functions.\n",
    "\n",
    "It may be created from any [langchain chat model](https://python.langchain.com/v0.1/docs/modules/model_io/chat/) or runnable. For convenience, you may also instantiate directly from Ollama or \n",
    "\n",
    "Optional: you can use `APIKeyChain` to retrive API keys from a json file. It is a `dict` subclass with the `from_json_file` method that will simply read a json file as a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot(model_type=ChatOpenAI, model_name=\"gpt-4o-mini\", tools=None)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "keychain = simplechatbot.APIKeyChain.from_json_file('../scripts/keys.json')\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o-mini', api_key=keychain['openai'])\n",
    "chatbot = simplechatbot.ChatBot.from_model(model=model)\n",
    "print(chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an ollama instance running on your machine, you can use the `from_ollama` constructor. You only need the model name and the `ChatOllma` constructor will identify the model API endpoint location as long as it is local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = simplechatbot.ChatBot.from_ollama(\n",
    "    model_name = 'llama3.1', \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may do the same for `ChatOpenAI` using `from_openai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = simplechatbot.ChatBot.from_openai(\n",
    "    model_name = 'gpt-4o-mini', \n",
    "    api_key=keychain['openai'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `system_prompt` parameter to initialize the chatbot with instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "You are a creative designer who has been tasked with creating a new slogan for a company.\n",
    "The user will describe the company, and you will need to generate three slogan ideas for them.\n",
    "'''\n",
    "chatbot = simplechatbot.ChatBot.from_ollama(\n",
    "    model_name = 'llama3.1', \n",
    "    system_prompt=system_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tools` parameter allows you to pass any [langchain tools](https://python.langchain.com/v0.1/docs/modules/tools/) you want your chatbot to be able to use. You can use one of [Langchain's built-in tools](https://python.langchain.com/v0.1/docs/integrations/tools/) (such as `DuckDuckGoSearchResults`) or [define your own custom tools](https://python.langchain.com/v0.1/docs/modules/tools/custom_tools/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "tools = [\n",
    "    DuckDuckGoSearchResults(\n",
    "        keys_to_include=['snippet', 'title'], \n",
    "        results_separator='\\n\\n',\n",
    "        num_results = 4,\n",
    "    ),\n",
    "]\n",
    "\n",
    "chatbot = simplechatbot.ChatBot.from_ollama(\n",
    "    model_name = 'llama3.1', \n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = '''\n",
    "Your job is to answer any questions the user has.\n",
    "'''\n",
    "chatbot = simplechatbot.ChatBot.from_openai(\n",
    "    model_name = 'gpt-4o-mini', \n",
    "    api_key=keychain['openai'],\n",
    "    system_prompt=system_prompt,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "reply = chatbot.chat('What is the capital of France?')\n",
    "reply.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ChatResult` and `ChatStream` Objects\n",
    "\n",
    "Calls to `chat` return `ChatResult` objects, which contain the message reply (`message`) and means with which to call any tools (`call_tools`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 104, 'output_tokens': 8, 'total_tokens': 112}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply.message.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 8,\n",
       "  'prompt_tokens': 104,\n",
       "  'total_tokens': 112,\n",
       "  'completion_tokens_details': {'reasoning_tokens': 0},\n",
       "  'prompt_tokens_details': {'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
       " 'system_fingerprint': 'fp_f85bea6784',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply.message.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See available tool calls using `tool_calls`. See how the question about the weather in Rome results in a tool call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.chat('What is the capital of France?').tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'duckduckgo_results_json',\n",
       "  'args': {'query': 'current weather in Rome'},\n",
       "  'id': 'call_wF7eMhgRjPAR3CNmlXQyuJZW',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply = chatbot.chat('What is the weather in Rome?')\n",
    "reply.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duckduckgo_results_json(query=current weather in Rome)\n"
     ]
    }
   ],
   "source": [
    "for tool_name, result in reply.call_tools().items():\n",
    "    print(result.tool_info_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls to `chat_stream` are very similar but instead return `ChatStream` objects. These objects are iterators and must be iterated over before you can call any tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris."
     ]
    }
   ],
   "source": [
    "for r in chatbot.chat_stream(f'What is the capital of France?'):\n",
    "    print(r.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exhausting the iterable, you can call `tool_calls` and `call_tools` to see and execute the requested tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Rome is sunny, with a few clouds expected. The temperature is peaking at around 79Â°F. During the night and early morning, there will be light air, and in the afternoon, a light breeze is anticipated, with gusts possibly reaching up to 21 mph."
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply_stream = chatbot.chat_stream(f'What is the weather in Rome?')\n",
    "for r in reply_stream:\n",
    "    print(r.content, end='', flush=True)\n",
    "\n",
    "reply_stream.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: do not call `call_tools` before completing the iterable because the chatbot may not have streamed all of the tool call information back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat User Interface\n",
    "Of course, what is a chatbot if you can't actually use it? To run an interactive command-line chat, use `.ui.start_interactive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to start interactive chat\n",
    "#chatbot.ui.start_interactive(stream=True, show_intro=True, show_tools=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
